{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mentoría \"Predicción de lluvias extremas\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TP 2: Análisis y Curación de Datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "Datos = pd.read_csv(\"https://raw.githubusercontent.com/Rondamon/2022_Mentoria_LluviasExtremas/master/dataset/datos_diarios_cordoba.csv\", parse_dates = True, index_col=\"fecha\")\n",
    "id_Datos = pd.read_csv(\"https://raw.githubusercontent.com/Rondamon/2022_Mentoria_LluviasExtremas/master/dataset/metadatos_estaciones.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CONSIGNA TP2:\n",
    "\n",
    "En este TP, nos enfocaremos en la cuenca del río Carcarañá. Por lo tanto, las estaciones que utilizaremos del dataset anterior son las siguientes:\n",
    "- Pilar\n",
    "- Rio Cuarto\n",
    "- Marcos Juarez\n",
    "- La Florida\n",
    "- Pueblo Andino\n",
    "En todos los casos, considerar el año hidrológico como del 1/agosto al 31/julio.\n",
    "\n",
    "\n",
    "## 1. Análisis y curación de datos de una API - formato JSON\n",
    "\n",
    "Referencias: https://darksky.net/dev/docs\n",
    "\n",
    "  1. Extraer los datos para las coordenadas de las estaciones antes indicadas.\n",
    "  2. ¿Cuántos años de datos hay?\n",
    "  3. ¿Existen valores faltantes? Cuantificarlos.\n",
    "  3. Generar un nuevo dataset a partir de los datos (time, summary, precipAccumulation, temperature, humidity, pressure, windSpeed, uvIndex, temperatureMin, temperatureMax.\n",
    "  4. Hacer las conversiones de unidades necesarias a estos datos para poder compararlos con el dataset \"datos_diarios_cordoba.csv\".\n",
    "  5. Comparar los estadísticos de estos datasets con los de cada estación.\n",
    "\n",
    "\n",
    "## 2. Análisis y curación de datos de un Excel y un TXT\n",
    "\n",
    "Referencias TerraClimate: http://www.climatologylab.org/terraclimate.html\n",
    "\n",
    "  1. Leer los datos de \"TerraClimate.csv\" y determinar para cada variable los valores promedios anuales (correspondiente a cada año hidrológico).\n",
    "  2. Hacer las conversiones de unidades necesarias para poder compararlos con cada estación.\n",
    "  3. Determinar para las estaciones de la cuenca del Carcarañá, los valores promedios anuales (año hidrológico) y comparar los estadísticos de este dataset con los de \"datos_diarios_cordoba.csv\".\n",
    "  4. Utilizar el dataset de TerraClimate para rellenar los datos faltantes en \"datos_diarios_cordoba.csv\" y guardar como un dataset nuevo. Hacer esto para todas las variables salvo para lluvia.\n",
    "  5. Agregar las demás variables del dataset de TerraClimate al creado en el punto 4. \n",
    "\n",
    "\n",
    "## 3. Análisis y curación de datos de un Excel y un TXT\n",
    "\n",
    "Referencias CHIRPS: https://disasters.nasa.gov/instruments/imerg\n",
    "\n",
    "  1. En cada año hidrológico, leer los datos de \"CHIRPS.txt\" y determinar la Precipitaciones Máximas Diarias Anuales (PMDA) y las Precipitaciones Totales Anuales para cada estación.\n",
    "  2. Graficar y comparar los estadísticos de estos datasets con los de cada estación (dataset \"datos_diarios_cordoba.csv\").\n",
    "  3. ¿Es posible rellenar la serie del dataset \"datos_diarios_cordoba.csv\"?\n",
    "  4. Agregar los nuevos features al dataset creado en el punto 5 de la parte 2 y exportar el dataset nuevo en formato csv.\n",
    "  5. A partir del dataset del punto 4, elaborar matrices de correlación entre las diferentes variables y las series de Precipitaciones Máximas Diarias Anuales (PMDA) para cada estación.\n",
    "\n",
    "\n",
    "## 4. Análisis y curación de Índices Climáticos en Excel\n",
    "\n",
    "Referencias: https://psl.noaa.gov/data/climateindices/list/\n",
    "\n",
    "  1. Leer el archivo \"indices_clim.xlsx\" y evaluar la cantidad de valores faltantes.\n",
    "  2. Convertir los datos faltantes en NaN.\n",
    "  3. Hacer matrices de correlación entre los diferentes índices climáticos y las series de Precipitaciones Máximas Diarias Anuales (PMDA) en las diferentes estaciones. Hacer esto para cada año hidrológico.\n",
    "  4. Repetir lo mismo para la serie de caudales máximos diarios anuales (QMDA) en Pueblo Andino."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ayuda Parte 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "import requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "baseUrl = \"https://api.darksky.net/forecast/<key>/<longitude>,<latitude>,<date>?exclude=flags,hourly&units=ca\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Tiempo en formato UNIX, cuenta los segundos desde el 1ro de Enero del 1970 en GMT\n",
    "#Las coordenadas actuales son las de Marcos Juarez\n",
    "replacedUrl = baseUrl.replace(\"<key>\", \"9349598e9f11f5eddceb6791daa6d787\").replace(\"<longitude>\", \"-64.533333\").replace(\"<latitude>\", \"-32.066667\").replace(\"<date>\", \"1559362638\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "r = requests.get(url = replacedUrl) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'latitude': -64.533333,\n",
       " 'longitude': -32.066667,\n",
       " 'timezone': 'Etc/GMT+2',\n",
       " 'currently': {'time': 1559362638, 'uvIndex': 0},\n",
       " 'offset': -2}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = r.json()\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
